{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7\n"
     ]
    }
   ],
   "source": [
    "#nltk\n",
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#gensim\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgensim\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(gensim\u001b[39m.\u001b[39m__version__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m'\u001b[39m\u001b[39mgensim\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m logger\u001b[39m.\u001b[39mhandlers:  \u001b[39m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mindexedcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m IndexedCorpus  \u001b[39m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmmcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m MmCorpus  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbleicorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m BleiCorpus  \u001b[39m# noqa:F401\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIndexedCorpus\u001b[39;00m(interfaces\u001b[39m.\u001b[39mCorpusABC):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/interfaces.py:19\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[39mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCorpusABC\u001b[39;00m(utils\u001b[39m.\u001b[39mSaveLoad):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/matutils.py:1031\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mlen\u001b[39m(set1 \u001b[39m&\u001b[39m set2)) \u001b[39m/\u001b[39m \u001b[39mfloat\u001b[39m(union_cardinality)\n\u001b[1;32m   1029\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1030\u001b[0m     \u001b[39m# try to load fast, cythonized code if possible\u001b[39;00m\n\u001b[0;32m-> 1031\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_matutils\u001b[39;00m \u001b[39mimport\u001b[39;00m logsumexp, mean_absolute_difference, dirichlet_expectation\n\u001b[1;32m   1033\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m   1034\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mlogsumexp\u001b[39m(x):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gensim/_matutils.pyx:1\u001b[0m, in \u001b[0;36minit gensim._matutils\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "#gensim\n",
    "import gensim\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer sous forme de liste\n",
    "\n",
    "#Minuscules\n",
    "corpus = \"La révolution industrielle a marqué une étape majeure dans l'histoire de l'humanité. Elle a permis de transformer radicalement les modes de production et de consommation, et d'améliorer significativement les conditions de vie des populations. Grâce à l'industrialisation, les pays ont pu se doter d'une économie plus dynamique et plus performante. De nouvelles technologies ont vu le jour, favorisant ainsi l'essor de l'innovation et de la recherche. La révolution industrielle a également contribué à l'émergence de grandes puissances économiques, notamment en Europe et en Amérique du Nord.\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la révolution industrielle a marqué une étape majeure dans lhistoire de lhumanité elle a permis de transformer radicalement les modes de production et de consommation et daméliorer significativement les conditions de vie des populations grâce à lindustrialisation les pays ont pu se doter dune économie plus dynamique et plus performante de nouvelles technologies ont vu le jour favorisant ainsi lessor de linnovation et de la recherche la révolution industrielle a également contribué à lémergence de grandes puissances économiques notamment en europe et en amérique du nord\n"
     ]
    }
   ],
   "source": [
    "#retrait des ponctuations\n",
    "import re\n",
    "corpus = re.sub(r'[^\\w\\s]','',corpus)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Tokénisation avec nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bernoud/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modèle de tokénisation\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la révolution industrielle a marqué une étape majeure dans lhistoire de lhumanité elle a permis de transformer radicalement les modes de production et de consommation et daméliorer significativement les conditions de vie des populations grâce à lindustrialisation les pays ont pu se doter dune économie plus dynamique et plus performante de nouvelles technologies ont vu le jour favorisant ainsi lessor de linnovation et de la recherche la révolution industrielle a également contribué à lémergence de grandes puissances économiques notamment en europe et en amérique du nord\n",
      "['la', 'révolution', 'industrielle', 'a', 'marqué', 'une', 'étape', 'majeure', 'dans', 'lhistoire', 'de', 'lhumanité', 'elle', 'a', 'permis', 'de', 'transformer', 'radicalement', 'les', 'modes', 'de', 'production', 'et', 'de', 'consommation', 'et', 'daméliorer', 'significativement', 'les', 'conditions', 'de', 'vie', 'des', 'populations', 'grâce', 'à', 'lindustrialisation', 'les', 'pays', 'ont', 'pu', 'se', 'doter', 'dune', 'économie', 'plus', 'dynamique', 'et', 'plus', 'performante', 'de', 'nouvelles', 'technologies', 'ont', 'vu', 'le', 'jour', 'favorisant', 'ainsi', 'lessor', 'de', 'linnovation', 'et', 'de', 'la', 'recherche', 'la', 'révolution', 'industrielle', 'a', 'également', 'contribué', 'à', 'lémergence', 'de', 'grandes', 'puissances', 'économiques', 'notamment', 'en', 'europe', 'et', 'en', 'amérique', 'du', 'nord']\n"
     ]
    }
   ],
   "source": [
    "#transformer le corpus en list de listes (docs) par tokénisation\n",
    "from nltk.tokenize import word_tokenize\n",
    "corpus_tk = word_tokenize(corpus)\n",
    "\n",
    "#avant tokénisation\n",
    "print(corpus)\n",
    "\n",
    "#après tokénisation\n",
    "print(corpus_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/bernoud/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /home/bernoud/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importation librairie pour lemantisation\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['la', 'révolution', 'industrielle', 'a', 'marqué', 'une', 'étape', 'majeure', 'dans', 'lhistoire', 'de', 'lhumanité', 'elle', 'a', 'permis', 'de', 'transformer', 'radicalement', 'le', 'mode', 'de', 'production', 'et', 'de', 'consommation', 'et', 'daméliorer', 'significativement', 'le', 'condition', 'de', 'vie', 'de', 'population', 'grâce', 'à', 'lindustrialisation', 'le', 'pay', 'ont', 'pu', 'se', 'doter', 'dune', 'économie', 'plus', 'dynamique', 'et', 'plus', 'performante', 'de', 'nouvelles', 'technology', 'ont', 'vu', 'le', 'jour', 'favorisant', 'ainsi', 'lessor', 'de', 'linnovation', 'et', 'de', 'la', 'recherche', 'la', 'révolution', 'industrielle', 'a', 'également', 'contribué', 'à', 'lémergence', 'de', 'grandes', 'puissance', 'économiques', 'notamment', 'en', 'europe', 'et', 'en', 'amérique', 'du', 'nord']\n"
     ]
    }
   ],
   "source": [
    "#lemmatisation\n",
    "#normalise un texte suivant le context identifié\n",
    "# ex (suis,es,est,sommes,êtes,sont ==> être)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "corpus_ln = [lem.lemmatize(word) for word in corpus_tk]\n",
    "print(corpus_ln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Paul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importer la librairie des stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "#charger les stopwords, en anglais pour le test\n",
    "#les stopwords sont des mots qui apporte du bruit à l'analyse, on souhaite les retirer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('french')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On pourrait rajouter des stopwords lier à un théme \n",
    "#ex théme du cinéma\n",
    "# stop_words.extend(['movie', 'film','story'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['révolution', 'industrielle', 'a', 'marqué', 'étape', 'majeure', 'lhistoire', 'lhumanité', 'a', 'permis', 'transformer', 'radicalement', 'mode', 'production', 'consommation', 'daméliorer', 'significativement', 'condition', 'vie', 'population', 'grâce', 'lindustrialisation', 'pay', 'pu', 'doter', 'dune', 'économie', 'plus', 'dynamique', 'plus', 'performante', 'nouvelles', 'technology', 'vu', 'jour', 'favorisant', 'ainsi', 'lessor', 'linnovation', 'recherche', 'révolution', 'industrielle', 'a', 'également', 'contribué', 'lémergence', 'grandes', 'puissance', 'économiques', 'notamment', 'europe', 'amérique', 'nord']\n"
     ]
    }
   ],
   "source": [
    "#suppression des stopwords\n",
    "corpus_sw = [mot for mot in corpus_ln if not mot in stop_words]\n",
    "print(corpus_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['révolution', 'industrielle', 'marqué', 'étape', 'majeure', 'lhistoire', 'lhumanité', 'permis', 'transformer', 'radicalement', 'mode', 'production', 'consommation', 'daméliorer', 'significativement', 'condition', 'vie', 'population', 'grâce', 'lindustrialisation', 'pay', 'doter', 'dune', 'économie', 'plus', 'dynamique', 'plus', 'performante', 'nouvelles', 'technology', 'jour', 'favorisant', 'ainsi', 'lessor', 'linnovation', 'recherche', 'révolution', 'industrielle', 'également', 'contribué', 'lémergence', 'grandes', 'puissance', 'économiques', 'notamment', 'europe', 'amérique', 'nord']\n"
     ]
    }
   ],
   "source": [
    "#retirer les tokens de moins de 3 lettres (génère du bruit)\n",
    "corpus_sw = [mot for mot in corpus_sw if len(mot) >= 3]\n",
    "print(corpus_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling avec Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<45 unique tokens: ['ainsi', 'amérique', 'condition', 'consommation', 'contribué']...>\n"
     ]
    }
   ],
   "source": [
    "#construction d'un dictionnaire des tokens\n",
    "from gensim.corpora import Dictionary\n",
    "dico = Dictionary([corpus_sw[:]])\n",
    "print(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ainsi': 0, 'amérique': 1, 'condition': 2, 'consommation': 3, 'contribué': 4, 'daméliorer': 5, 'doter': 6, 'dune': 7, 'dynamique': 8, 'europe': 9, 'favorisant': 10, 'grandes': 11, 'grâce': 12, 'industrielle': 13, 'jour': 14, 'lessor': 15, 'lhistoire': 16, 'lhumanité': 17, 'lindustrialisation': 18, 'linnovation': 19, 'lémergence': 20, 'majeure': 21, 'marqué': 22, 'mode': 23, 'nord': 24, 'notamment': 25, 'nouvelles': 26, 'pay': 27, 'performante': 28, 'permis': 29, 'plus': 30, 'population': 31, 'production': 32, 'puissance': 33, 'radicalement': 34, 'recherche': 35, 'révolution': 36, 'significativement': 37, 'technology': 38, 'transformer': 39, 'vie': 40, 'économie': 41, 'économiques': 42, 'également': 43, 'étape': 44}\n"
     ]
    }
   ],
   "source": [
    "#list des tokens et leurs numéros internes\n",
    "print(dico.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ainsi', 'amérique', 'condition', 'consommation', 'contribué', 'daméliorer', 'doter', 'dune', 'dynamique', 'europe', 'favorisant', 'grandes', 'grâce', 'industrielle', 'industrielle', 'jour', 'lessor', 'lhistoire', 'lhumanité', 'lindustrialisation', 'linnovation', 'lémergence', 'majeure', 'marqué', 'mode', 'nord', 'notamment', 'nouvelles', 'pay', 'performante', 'permis', 'plus', 'plus', 'population', 'production', 'puissance', 'radicalement', 'recherche', 'révolution', 'révolution', 'significativement', 'technology', 'transformer', 'vie', 'économie', 'économiques', 'également', 'étape']\n",
      "\n",
      "\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 2), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 2), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#représentation bag of words des documents\n",
    "corpus_bow = [dico.doc2bow(corpus_sw)]\n",
    "\n",
    "#identification\n",
    "print(sorted(corpus_sw))\n",
    "\n",
    "#et en bow\n",
    "print('\\n')\n",
    "print(corpus_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA\n",
    "#Latent Dirichlet Allocation\n",
    "from gensim.models import LdaModel\n",
    "lda = LdaModel(corpus=corpus_bow,id2word=dico, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'révolution'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#affichage des topics\n",
    "lda.show_topic(0)[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
